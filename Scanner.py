from langchain.text_splitter import Language
from langchain.document_loaders.generic import GenericLoader
from langchain.document_loaders.parsers import LanguageParser

from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate
 
from langchain.chat_models import ChatOpenAI
 
from langchain.output_parsers import StructuredOutputParser, ResponseSchema

# Load js file
loader = GenericLoader.from_filesystem("",
                                        glob = "**/*",
                                       suffixes=[".js"],
                                       parser = LanguageParser(language=Language.JS, parser_threshold=500)
)

documents = loader.load()

response_schemas = [
    ResponseSchema(name="Vulnerability", description="Vulnerability found in the given input."),
    ResponseSchema(name="Description", description="Brief description of the descovered vulnerability."),
]

# The parser that will look for the LLM output in my schema and return it back to me
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)

# The format instructions that LangChain makes. Let's look at them
format_instructions = output_parser.get_format_instructions()
 
chat_model = ChatOpenAI(openai_api_key="",temperature=0.5, model_name='gpt-4')

# The prompt template that brings it all together
prompt = ChatPromptTemplate(
    messages=[
        HumanMessagePromptTemplate.from_template("""You are a source code vulnerability scanner. Given a text input, discover vulnerabilities along with the description of the vulnerability. 
        \n{format_instructions}\n{user_prompt}""")  
    ],
    input_variables=["user_prompt"],
    partial_variables={"format_instructions": format_instructions}

)

user_query = prompt.format_prompt(user_prompt = documents[0])
user_query_output = chat_model(user_query.to_messages())
 
print(user_query_output.content)

